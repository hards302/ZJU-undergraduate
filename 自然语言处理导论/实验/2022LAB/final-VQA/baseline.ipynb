{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "from easydict import EasyDict as edict\n",
    "from mindspore import dataset as ds\n",
    "import os\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context\n",
    "context.set_context(mode=context.PYNATIVE_MODE, save_graphs=False, device_target='CPU')\n",
    "# CONFIG\n",
    "cfg = edict({\n",
    "    'question_embdim': 512,\n",
    "    'image_embdim': 512,\n",
    "    'outdim': 1024,\n",
    "    'dropout': 0.1,\n",
    "    'answer_num': 8193,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 2,\n",
    "    'batch_size': 256,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQA_baseline(nn.Cell):\n",
    "\n",
    "    def __init__(self, config, auto_prefix=True, flags=None):\n",
    "        '''\n",
    "        config:{\n",
    "            question_embdim 问题句嵌入dim\n",
    "            image_embdim 图片嵌入dim\n",
    "            outdim 输出dim\n",
    "            dropout \n",
    "            answer_num\n",
    "        }\n",
    "        '''\n",
    "        super().__init__(auto_prefix, flags)\n",
    "        self.question_dense = nn.Dense(config.question_embdim, config.outdim)\n",
    "        self.image_dense = nn.Dense(config.image_embdim, config.outdim)\n",
    "        self.dropout = nn.Dropout(1 - config.dropout)\n",
    "        self.out_dense_1 = nn.Dense(config.outdim, 256)\n",
    "        self.out_dense_2 = nn.Dense(256, config.answer_num)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, ques, img):\n",
    "        '''\n",
    "        img:[B, image_embdim]\n",
    "        ques:[B, question_embdim]\n",
    "        output:[B, answer_num]\n",
    "        '''\n",
    "        ques_out = self.relu(self.question_dense(ques))\n",
    "        img_out = self.relu(self.image_dense(img))\n",
    "        c = self.relu(self.out_dense_1(ques_out * img_out))\n",
    "        c = self.out_dense_2(c)\n",
    "        output = self.dropout(c)\n",
    "        return output\n",
    "\n",
    "class WithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, config):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self.batch_size = config.batch_size\n",
    "        self.loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\n",
    "    def construct(self, ques_emb, img_emb, label):\n",
    "        out = self._backbone(ques_emb, img_emb)\n",
    "        loss = self.loss(out, label)\n",
    "        return loss\n",
    "\n",
    "class EvalCell(nn.Cell):\n",
    "    def __init__(self, backbone):\n",
    "        super(EvalCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self.onehot = ops.OneHot()\n",
    "        self.print = ops.Print()\n",
    "    def construct(self, ques_emb, img_emb, label):\n",
    "        out = self._backbone(ques_emb, img_emb)\n",
    "        return (out, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(batch_size, dir_path = \"./\", repeat_num = 1, is_training = True):\n",
    "\n",
    "    if is_training:\n",
    "        data_dir = os.path.join(dir_path, \"trainval.mindrecord\")\n",
    "    else:\n",
    "        data_dir = os.path.join(dir_path, \"test.mindrecord\")\n",
    "    data_set = ds.MindDataset(data_dir, columns_list=[\"ques_emb\",\"img_emb\", \"label\"], num_shards=1, shard_id=0)\n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    data_set = data_set.repeat(count=repeat_num)\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "train_dataset = create_dataset(cfg.batch_size)\n",
    "# create model\n",
    "vqa_baseline = VQA_baseline(cfg)\n",
    "vqa_with_loss = WithLossCell(vqa_baseline, cfg)\n",
    "vqa_with_acc = EvalCell(vqa_baseline)\n",
    "opt = nn.Adam(vqa_with_loss.trainable_params(), learning_rate=cfg.learning_rate)\n",
    "model = Model(vqa_with_loss, eval_network=vqa_with_acc, metrics={'acc'}, optimizer=opt)\n",
    "# create callback\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=128, keep_checkpoint_max=32)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"hzw\", directory=\"./checkpoint\", config=config_ck)\n",
    "loss_cb = LossMonitor()\n",
    "cb = [loss_cb, ckpoint_cb]\n",
    "# start training\n",
    "print(\"start training...\")\n",
    "model.train(cfg.epochs, train_dataset, callbacks=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = create_dataset(cfg.batch_size, is_training=False)\n",
    "acc = model.eval(eval_dataset)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57adb5802fb0f8cfd5535bab284b845a3df436c091fabcc1c6f978836181b2be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
